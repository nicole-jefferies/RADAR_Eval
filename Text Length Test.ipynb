{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicole/miniconda3/envs/radar_env/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detector and tokeniser successfully loaded\n"
     ]
    }
   ],
   "source": [
    "from RADAR_set_up import *\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_RADAR_data = pd.read_csv('topics-post-RADAR-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paragraph Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUD_paragraph_counts = []\n",
    "\n",
    "for text in post_RADAR_data['Student']:\n",
    "    text = text.strip('/n')\n",
    "    STUD_paragraph_counts.append(text.count('\\n')); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(3,11)]\n",
    "y = [STUD_paragraph_counts.count(i) for i in range(3,11)]\n",
    "f = plt.bar(x, y)\n",
    "\n",
    "plt.title('Paragraphs Distributions of Human Texts')\n",
    "plt.xlabel('Number of Paragraphs')\n",
    "plt.ylabel('Number of Texts')\n",
    "\n",
    "for i in range(len(x)):\n",
    "    plt.text(x[i], y[i], str(y[i]), ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making DF for Text Length Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>File</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Student</th>\n",
       "      <th>Student_Reformatted</th>\n",
       "      <th>Grammarly_Score</th>\n",
       "      <th>STUD_Grammarly_Red</th>\n",
       "      <th>STUD_Grammarly_All</th>\n",
       "      <th>ChatGPT-3</th>\n",
       "      <th>ChatGPT-4</th>\n",
       "      <th>...</th>\n",
       "      <th>STUD_REFORMATTED</th>\n",
       "      <th>STUD_RED_RADAR</th>\n",
       "      <th>STUD_ALL_RADAR</th>\n",
       "      <th>GPT3_RADAR</th>\n",
       "      <th>GPT4_RADAR</th>\n",
       "      <th>GPT4_Quillbot_RADAR</th>\n",
       "      <th>GPT4_Grammarly_RADAR</th>\n",
       "      <th>GPT4_WordAI_RADAR</th>\n",
       "      <th>GPT4_Paraphrasing_IO_RAW_RADAR</th>\n",
       "      <th>GPT4_Paraphrasing_IO_EDITED_RADAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>essay01.txt</td>\n",
       "      <td>Should students be taught to compete or to coo...</td>\n",
       "      <td>It is always said that competition can effecti...</td>\n",
       "      <td>It is always said that competition can effecti...</td>\n",
       "      <td>75</td>\n",
       "      <td>It is always said that competition can effecti...</td>\n",
       "      <td>It is always said that competition can effecti...</td>\n",
       "      <td>Education is not only about acquiring knowledg...</td>\n",
       "      <td>Title: Fostering Cooperation and Competition i...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519651</td>\n",
       "      <td>0.712787</td>\n",
       "      <td>0.704968</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.974493</td>\n",
       "      <td>0.975968</td>\n",
       "      <td>0.963674</td>\n",
       "      <td>0.843616</td>\n",
       "      <td>0.989108</td>\n",
       "      <td>0.983982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         File                                              Topic  \\\n",
       "0   0  essay01.txt  Should students be taught to compete or to coo...   \n",
       "\n",
       "                                             Student  \\\n",
       "0  It is always said that competition can effecti...   \n",
       "\n",
       "                                 Student_Reformatted  Grammarly_Score  \\\n",
       "0  It is always said that competition can effecti...               75   \n",
       "\n",
       "                                  STUD_Grammarly_Red  \\\n",
       "0  It is always said that competition can effecti...   \n",
       "\n",
       "                                  STUD_Grammarly_All  \\\n",
       "0  It is always said that competition can effecti...   \n",
       "\n",
       "                                           ChatGPT-3  \\\n",
       "0  Education is not only about acquiring knowledg...   \n",
       "\n",
       "                                           ChatGPT-4  ... STUD_REFORMATTED  \\\n",
       "0  Title: Fostering Cooperation and Competition i...  ...         0.519651   \n",
       "\n",
       "  STUD_RED_RADAR STUD_ALL_RADAR GPT3_RADAR GPT4_RADAR  GPT4_Quillbot_RADAR  \\\n",
       "0       0.712787       0.704968   0.986301   0.974493             0.975968   \n",
       "\n",
       "   GPT4_Grammarly_RADAR  GPT4_WordAI_RADAR  GPT4_Paraphrasing_IO_RAW_RADAR  \\\n",
       "0              0.963674           0.843616                        0.989108   \n",
       "\n",
       "   GPT4_Paraphrasing_IO_EDITED_RADAR  \n",
       "0                           0.983982  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_RADAR_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length_data = []\n",
    "for text_index, text in enumerate(post_RADAR_data['Student']):\n",
    "    text = text.strip('\\n')\n",
    "    paragraphs = text.split('\\n')\n",
    "    curr = \"\"\n",
    "    for para_index, para in enumerate(paragraphs):\n",
    "        curr = curr + '\\n' + para\n",
    "        text_length_data.append(\n",
    "            {\n",
    "                'text_id': text_index,\n",
    "                'pre_processed_text' : curr.strip('\\n'),\n",
    "                'paragraph_id' : para_index,\n",
    "                'word_count' : len(re.findall(r'\\b\\w+\\b', curr)),\n",
    "            }\n",
    "        )\n",
    "text_length_data = pd.DataFrame(text_length_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>pre_processed_text</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>It is always said that competition can effecti...</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                 pre_processed_text  paragraph_id  \\\n",
       "0        0  It is always said that competition can effecti...             0   \n",
       "\n",
       "   word_count  \n",
       "0          84  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_length_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting RADAR Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-41490fb41478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mradarOutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetRADARoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_length_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pre_processed_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-41490fb41478>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mradarOutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetRADARoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_length_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pre_processed_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/TOPICS/RADAR/RADAR_set_up.py\u001b[0m in \u001b[0;36mgetRADARoutput\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/radar_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/radar_env/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         )\n\u001b[1;32m   1227\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/radar_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/radar_env/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m         )\n\u001b[1;32m    864\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/radar_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/radar_env/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    532\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m                 )\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/radar_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/radar_env/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         )\n\u001b[1;32m    418\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/radar_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/radar_env/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         )\n\u001b[1;32m    347\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/radar_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/radar_env/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/radar_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/radar_env/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "radarOutputs = [getRADARoutput(text) for text in text_length_data['pre_processed_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length_data['RADAR_outputs'] = radarOutputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting Resulting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length_data.to_csv('topics-length-specific-RADAR.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radar_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
